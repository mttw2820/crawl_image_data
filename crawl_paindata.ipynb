{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.0\n"
     ]
    }
   ],
   "source": [
    "# test selenium\n",
    "import selenium\n",
    "print(selenium.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from selenium import webdriver\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "import math\n",
    "\n",
    "# for selenium\n",
    "chrome_driver_path = 'C:\\chromedriver\\chromedriver.exe'\n",
    "common_url = 'https://google.com'\n",
    "common_rawdata_path = \"./data/webdata/crawling_data/raw_data/\"\n",
    "common_facedata_path = \"./data/webdata/crawling_data/faces/\"\n",
    "\n",
    "# for dlib\n",
    "ALL = list(range(0, 68))\n",
    "RIGHT_EYEBROW = list(range(17, 22))\n",
    "LEFT_EYEBROW = list(range(22, 27))\n",
    "NOSE = list(range(27, 36))\n",
    "RIGHT_EYE = list(range(36, 42))\n",
    "LEFT_EYE = list(range(42, 48))\n",
    "MOUTH_OUTLINE = list(range(61, 68))\n",
    "JAWLINE = list(range(0, 17))\n",
    "INDEX = ALL\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "outer_border = 50\n",
    "inner_border = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_face(faces, path) :\n",
    "    if len(faces) == 0 :\n",
    "        print(\"zero face detected in \", path)\n",
    "        return -1\n",
    "    else : print(str(len(faces)) + \" faces are detected.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_ppl(f) :\n",
    "    w = f.right() - f.left()\n",
    "    h = f.bottom() - f.top()\n",
    "    if w > h : h = w\n",
    "    else : w = h\n",
    "    x1 = f.left() - w\n",
    "    y1 = f.top() - h\n",
    "    x2 = f.left() + 2*w\n",
    "    y2 = f.top() + 2*h\n",
    "    \n",
    "    crop_img = img[y1:y2, x1:x2]\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(face, img) :\n",
    "    landmarks = predictor(img, face)\n",
    "    landmark_list = []\n",
    "    \n",
    "    for p in landmarks.parts():\n",
    "        landmark_list.append([p.x, p.y])\n",
    "    landmark_list = np.array(landmark_list)\n",
    "\n",
    "    face_mid = []\n",
    "    for i, pt in enumerate(landmark_list[INDEX]):\n",
    "        pt_pos = (pt[0], pt[1])\n",
    "        if i == 33 : nose_end = pt_pos\n",
    "        elif i == 27 : nose_start = pt_pos\n",
    "        elif i == 16 : face_right = pt_pos\n",
    "        elif i == 9 : face_mid.append(pt_pos)\n",
    "        elif i == 8 : face_mid.append(pt_pos)\n",
    "        elif i == 7 : face_mid.append(pt_pos)\n",
    "        elif i == 0 : face_left = pt_pos\n",
    "                \n",
    "    return (face_left, face_right, nose_start, nose_end, face_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(faces, img) :\n",
    "    print(str(len(faces)) + \" faces are here!!\")\n",
    "    for face in faces : \n",
    "        landmarks = predictor(img, face)\n",
    "        landmark_list = []\n",
    "        \n",
    "        for p in landmarks.parts():\n",
    "            landmark_list.append([p.x, p.y])\n",
    "        landmark_list = np.array(landmark_list)\n",
    "\n",
    "        for i, pt in enumerate(landmark_list[INDEX]):\n",
    "            pt_pos = (pt[0], pt[1])\n",
    "            if i==0 :\n",
    "                point_f = pt_pos\n",
    "                cv2.circle(img, pt_pos, 2, (255, 0, 0), -1)\n",
    "            elif i==27 : \n",
    "                point_s = pt_pos\n",
    "                cv2.circle(img, pt_pos, 2, (0, 0, 255), -1)\n",
    "            elif i==33: \n",
    "                point_e = pt_pos\n",
    "                cv2.circle(img, pt_pos, 2, (0, 0, 255), -1)\n",
    "            else :\n",
    "                cv2.circle(img, pt_pos, 2, (0, 255, 0), -1)       \n",
    "                \n",
    "    #cv2.imwrite(landmark_path, img_landmark)\n",
    "    return (point_f, point_s, point_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_alignment(origin_w, origin_h, nose_start, nose_end, img) :\n",
    "    # vertical alignment\n",
    "    isRotated = False\n",
    "    angle = math.degrees(math.atan((nose_start[0] - nose_end[0])/([nose_end[1] - nose_start[1]])))\n",
    "    \n",
    "    if abs(angle)>=3 :\n",
    "        matrix = cv2.getRotationMatrix2D((nose_start[0], nose_start[1]), angle, 1)\n",
    "        rotated_img = cv2.warpAffine(img, matrix, (origin_w, origin_h))\n",
    "        isRotated = True\n",
    "        return (isRotated, rotated_img)\n",
    "        \n",
    "    return (isRotated, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_tight(face_right, face_left, nose_start, face_mid, img) :\n",
    "    mid_jaw_y = max(face_mid[0][1], face_mid[1][1], face_mid[2][1])\n",
    "    stand_h = mid_jaw_y - nose_start[1]\n",
    "    stand_w = 2.5 * stand_h / 2\n",
    "    start_x = nose_start[0] - stand_w\n",
    "    end_x = nose_start[0] + stand_w\n",
    "    start_y = nose_start[1] - int(1.2 * stand_h)\n",
    "    end_y = nose_start[1] + int(1.2 * stand_h)\n",
    "    \n",
    "    print(\"stand_w :\", stand_w, \" stand_h : \", stand_h, \" start_x : \", start_x, \" end_x : \", end_x, \" start_y : \", start_y, \" end_y : \", end_y)\n",
    "    try:\n",
    "        ## crop\n",
    "        cropped_img = img[int(start_y):int(end_y), int(start_x):int(end_x)]\n",
    "        ## resize\n",
    "        result_img = cv2.resize(cropped_img, dsize=(256, 256), interpolation = cv2.INTER_AREA)\n",
    "        return result_img\n",
    "    except Exception as e :\n",
    "        print(str(e))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 faces are detected.\n",
      "stand_w : 106.25  stand_h :  85  start_x :  27.75  end_x :  240.25  start_y :  48  end_y :  252\n",
      "./test_00.png\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "img_index = 1\n",
    "origin_img = cv2.imread(\"./test3.jpeg\")\n",
    "\n",
    "# 사이즈 초기화\n",
    "h, w, c = origin_img.shape\n",
    "if (h < 256) & (w < 256) :\n",
    "    _fx = 256*w/h\n",
    "    _fy = 256/h\n",
    "    origin_img = cv2.resize(origin_img, dsize=(0, 0), fx = _fx, fy = _fy, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "# 테두리 추가\n",
    "img = cv2.copyMakeBorder(origin_img, outer_border, outer_border, outer_border, outer_border, cv2.BORDER_REPLICATE)\n",
    "cv2.imwrite(\"./test_bordered.png\", img)\n",
    "\n",
    "# 얼굴 인식\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = detector(img_gray, 1)\n",
    "if check_face(faces, \"test\") < 0 : print(\"end\")\n",
    "else :\n",
    "    for face_index, face in enumerate(faces) :\n",
    "        # landmark 값 가져오기\n",
    "        origin_w, origin_h, origin_c = img.shape\n",
    "        face_left, face_right, nose_start, nose_end, face_mid = get_landmarks(face, img)\n",
    "        # rotate 이미지 생성\n",
    "        isRotated, rotated_img = face_alignment(origin_w, origin_h, nose_start, nose_end, crop_img)\n",
    "        cv2. imwrite(\"./test_rotated_\"+str(face_index).zfill(2)+\".png\", rotated_img)\n",
    "        \n",
    "        if isRotated :\n",
    "            img_gray_2 = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2GRAY)\n",
    "            faces_2 = detector(img_gray_2, 1)\n",
    "            face_left2, face_right2, nose_start2, nose_end2, face_mid2 = get_landmarks(faces_2[0], rotated_img)\n",
    "            result = crop_tight(face_right2, face_left2, nose_start2, face_mid2, rotated_img)\n",
    "        else :\n",
    "            result = crop_tight(face_right, face_left, nose_start, face_mid, img)\n",
    "\n",
    "        path = \"./test\" + \"_\" + str(face_index).zfill(2) + \".png\"\n",
    "        cv2.imwrite(path, result)\n",
    "        print(path)\n",
    "    \n",
    "        print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-3c1b011481e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# scroll down for more imgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"window.scrollBy(0, 1000)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrower\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//img[@class='rg_i Q4LuWd']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'browser' is not defined"
     ]
    }
   ],
   "source": [
    "search_list = ['soccer injury', 'olympic injury', 'women soccer injury', 'baseball injury']\n",
    "\n",
    "for search_term in search_list :\n",
    "    rawdata_path = common_rawdata_path + search_term + \"/\"\n",
    "    facedata_path = common_facedata_path + search_term + \"/\"\n",
    "    url = common_url + \"/search?q=\" + search_term + \"&tbm=isch\"\n",
    "    driver = webdriver.Chrome(chrome_driver_path)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # scroll down for more imgs\n",
    "    for i in range(10) : \n",
    "        browser.execute_script(\"window.scrollBy(0, 1000)\")\n",
    "    \n",
    "    for img_index, img in enumerate(brower.find_elements_by_xpath(\"//img[@class='rg_i Q4LuWd']\")) :\n",
    "        index = str(img_index).zfill(5)\n",
    "        rawdata_file = rawdata_path + \"_\" + index + \".png\"\n",
    "        img.screenshot(rawdata_file)\n",
    "        \n",
    "        origin_img = cv2.imread(rawdata_file)\n",
    "        img = cv2.copyMakeBorder(origin_img, outer_border, outer_border, outer_border, outer_border, cv2.BORDER_REPLICATE)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(img_gray, 1)\n",
    "        if(check_face(faces, rawdata_file) < 0) : continue\n",
    "        \n",
    "        for face_index, face in enumerate(faces) :\n",
    "            crop_img = crop_ppl(face)\n",
    "            face_left, face_right, nose_start, nose_end, face_mid = get_landmarks(face, crop_img)\n",
    "            draw_landmarks(crop_img, face)\n",
    "            isRotated, rotated_img = face_alignment(origin_w, origin_h, nose_start, nose_end, crop_img)\n",
    "            result = crop_tight(isRotated, face_right, face_left, nose_start, face_mid, rotated_img)\n",
    "            \n",
    "            facedata_file = facedata_path + \"_\" + index + \"_\" + str(face_index).zfill(2) + \".png\"\n",
    "            cv2.imwrite(facedata_file, result)\n",
    "    \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
